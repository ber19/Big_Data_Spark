{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.0.2.15:4040\n",
       "SparkContext available as 'sc' (version = 2.4.6, master = local[*], app id = local-1616272525874)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(nombre,StringType,true), StructField(puesto,StringType,true), StructField(salario,LongType,true))\n",
       "staticPersonas: org.apache.spark.sql.DataFrame = [_corrupt_record: string, batchTimestampMs: bigint ... 7 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "val schema = new StructType().add(\"nombre\",\"string\")\n",
    "                            .add(\"puesto\",\"string\")\n",
    "                            .add(\"salario\",\"long\")\n",
    "\n",
    "// Dataframe estatico\n",
    "val staticPersonas = spark.read.json(\"/home/vmuser/personas/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------------+------------+\n",
      "|       puesto|avg(salario)|\n",
      "+-------------+------------+\n",
      "|Desarrollador|        11.0|\n",
      "|     Analista|        15.0|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "streamingSalarios: org.apache.spark.sql.DataFrame = [nombre: string, puesto: string ... 1 more field]\n",
       "both: org.apache.spark.sql.DataFrame = [nombre: string, puesto: string ... 9 more fields]\n",
       "mediaSalario: org.apache.spark.sql.DataFrame = [puesto: string, avg(salario): double]\n",
       "query: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@446bd2b6\n",
       "res0: Boolean = false\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------------+------------+\n",
      "|       puesto|avg(salario)|\n",
      "+-------------+------------+\n",
      "|Desarrollador|        12.0|\n",
      "|     Analista|        17.0|\n",
      "+-------------+------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-------------+------------+\n",
      "|       puesto|avg(salario)|\n",
      "+-------------+------------+\n",
      "|Desarrollador|        12.4|\n",
      "|     Analista|        17.0|\n",
      "+-------------+------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-------------+------------------+\n",
      "|       puesto|      avg(salario)|\n",
      "+-------------+------------------+\n",
      "| JefeProyecto|              28.0|\n",
      "|Desarrollador|12.714285714285714|\n",
      "|     Analista|              17.0|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Dataframe dinamico\n",
    "val streamingSalarios = spark.readStream\n",
    "    .schema(schema)\n",
    "    .json(\"/home/vmuser/streamingSalarios/\")\n",
    "\n",
    "// Se realiza el join entre los Dataframes, para obtener uno\n",
    "val both = streamingSalarios.join(staticPersonas, \"nombre\")\n",
    "// Creamos una vista(tabla) del dataframe creado en el paso anterior\n",
    "both.createOrReplaceTempView(\"personas_salario\")\n",
    "\n",
    "// Definimos la query\n",
    "val mediaSalario = spark.sql(\"select puesto, avg(salario) from personas_salario group by puesto\")\n",
    "\n",
    "// Definimos el streaming\n",
    "val query = mediaSalario.writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .format(\"console\")\n",
    "    .start()\n",
    "\n",
    "// Ejecutamos el streaming\n",
    "query.awaitTermination(90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: java.util.UUID = 010c3678-443a-4b9c-bd0f-c6050a775a6a\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Muestra el id de la query\n",
    "query.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@3e808b9d\n",
      "+- *(5) HashAggregate(keys=[puesto#126], functions=[avg(salario#127L)])\n",
      "   +- StateStoreSave [puesto#126], state info [ checkpoint = file:/tmp/temporary-db35d3ff-2f42-434b-adab-ee4ea95592ce/state, runId = d34766c6-bcbb-4d61-b6db-430d499174eb, opId = 0, ver = 3, numPartitions = 200], Complete, 0, 2\n",
      "      +- *(4) HashAggregate(keys=[puesto#126], functions=[merge_avg(salario#127L)])\n",
      "         +- StateStoreRestore [puesto#126], state info [ checkpoint = file:/tmp/temporary-db35d3ff-2f42-434b-adab-ee4ea95592ce/state, runId = d34766c6-bcbb-4d61-b6db-430d499174eb, opId = 0, ver = 3, numPartitions = 200], 2\n",
      "            +- *(3) HashAggregate(keys=[puesto#126], functions=[merge_avg(salario#127L)])\n",
      "               +- Exchange hashpartitioning(puesto#126, 200)\n",
      "                  +- *(2) HashAggregate(keys=[puesto#126], functions=[partial_avg(salario#127L)])\n",
      "                     +- *(2) Project [puesto#126, salario#127L]\n",
      "                        +- *(2) BroadcastHashJoin [nombre#125], [nombre#14], Inner, BuildRight\n",
      "                           :- *(2) Project [nombre#125, puesto#126, salario#127L]\n",
      "                           :  +- *(2) Filter isnotnull(nombre#125)\n",
      "                           :     +- *(2) FileScan json [nombre#125,puesto#126,salario#127L] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/home/vmuser/streamingSalarios/salario5, file:/home/vmuser/streamingSalari..., PartitionFilters: [], PushedFilters: [IsNotNull(nombre)], ReadSchema: struct<nombre:string,puesto:string,salario:bigint>\n",
      "                           +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n",
      "                              +- *(1) Project [nombre#14]\n",
      "                                 +- *(1) Filter isnotnull(nombre#14)\n",
      "                                    +- *(1) FileScan json [nombre#14] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/home/vmuser/personas/commits, file:/home/vmuser/personas/offsets, file:/h..., PartitionFilters: [], PushedFilters: [IsNotNull(nombre)], ReadSchema: struct<nombre:string>\n"
     ]
    }
   ],
   "source": [
    "// Explica la query\n",
    "query.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: String = null\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Muestra el nombre de la query\n",
    "query.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.streaming.StreamingQueryProgress =\n",
       "{\n",
       "  \"id\" : \"010c3678-443a-4b9c-bd0f-c6050a775a6a\",\n",
       "  \"runId\" : \"d34766c6-bcbb-4d61-b6db-430d499174eb\",\n",
       "  \"name\" : null,\n",
       "  \"timestamp\" : \"2021-03-20T20:44:55.118Z\",\n",
       "  \"batchId\" : 4,\n",
       "  \"numInputRows\" : 0,\n",
       "  \"inputRowsPerSecond\" : 0.0,\n",
       "  \"processedRowsPerSecond\" : 0.0,\n",
       "  \"durationMs\" : {\n",
       "    \"getOffset\" : 4,\n",
       "    \"triggerExecution\" : 4\n",
       "  },\n",
       "  \"stateOperators\" : [ {\n",
       "    \"numRowsTotal\" : 3,\n",
       "    \"numRowsUpdated\" : 0,\n",
       "    \"memoryUsedBytes\" : 80615,\n",
       "    \"customMetrics\" : {\n",
       "      \"loadedMapCacheHitCount\" : 1200,\n",
       "      \"loadedMapCacheMissCount\" : 0,\n",
       "      \"stateOnCurrentVersionSizeBytes\" : 17991\n",
       "    }\n",
       "  } ],\n",
       "  \"sources\" : [ {\n",
       "    \"description\" : \"FileStreamSource[file:/home/vmuser/streamingSalarios]\",\n",
       "    \"startOffset\" : {\n",
       "      \"logOff..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Muestra un resumen de la query\n",
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: Boolean = false\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Regresa si la query esta activa\n",
    "query.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Detinene la query\n",
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11 (SPylon)",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
